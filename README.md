# Telecom Customer Churn – Prediction, SHAP Explainability, and Segmentation

## Overview
This project builds churn prediction models for telecom customers, explains model decisions using SHAP, and segments customers with K-Means to guide targeted retention strategies.

## Dataset
- **Source:** Telco Customer Churn (Kaggle)  
- **Link:** https://www.kaggle.com/datasets/blastchar/telco-customer-churn/data  
- Contains customer demographics, service usage, billing details, and churn labels.

## What’s Included
- `customer_churn_prediction_SMOTE.ipynb` — full workflow with outputs:
  - Data cleaning and preprocessing (scaling numeric, one-hot encoding categorical)
  - Model training & tuning: Random Forest, XGBoost, LightGBM
  - Class imbalance handling with class weights
  - Evaluation: Accuracy, Recall, AUC, ROC curves
  - SHAP global and local explanations for LightGBM
  - Customer segmentation with K-Means using churn probability + service features

## Key Results
- **Best model:** LightGBM (AUC ≈ 0.836, strong recall on churn class)
- **Top churn drivers (SHAP):** Contract type (month-to-month vs longer terms), Monthly charges, Tenure; payment method and online security/support also matter.
- **Segments (K=4):**
  - High risk: month-to-month, electronic check, fiber, short tenure
  - Elevated risk: month-to-month, electronic check, fiber, mid tenure
  - Low risk (loyal/premium): two-year, auto-pay credit card, DSL, long tenure
  - Low risk (low spend/no internet): two-year, mailed check, no internet

## How to Run
1. Install dependencies: `pip install -r requirements.txt`
2. Launch the notebook: `jupyter notebook customer_churn_prediction_SMOTE.ipynb`
3. (Optional) Re-run cells to regenerate outputs.

## Repository Structure
- `customer_churn_prediction_SMOTE.ipynb` — main analysis with outputs
- `requirements.txt` — dependencies
- `WA_Fn-UseC_-Telco-Customer-Churn.csv` — dataset file (place here if not present)
- `customer_data_with_clusters.csv` — clustered output (generated by the notebook)
- `plots/` — saved visualizations (if generated)

## Reproducibility Notes
- Uses scikit-learn pipelines and GridSearchCV; random_state is set for comparability.
- Ensure the Kaggle dataset is present at the project root before running.